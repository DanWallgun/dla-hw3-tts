{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from audio import tools\n",
    "from configs import train_config\n",
    "\n",
    "all_wav_names = sorted(os.listdir(train_config.wav_path))\n",
    "def proc(index):\n",
    "    _, energy, pitch = tools.get_mel_v2_energy_pitch(\n",
    "        os.path.join(train_config.wav_path, all_wav_names[index])\n",
    "    )\n",
    "    np.save(\n",
    "        os.path.join(train_config.energy_path, 'ljspeech-energy-%05d.npy' % index),\n",
    "        energy, allow_pickle=False\n",
    "    )\n",
    "    np.save(\n",
    "        os.path.join(train_config.pitch_path, 'ljspeech-pitch-%05d.npy' % index),\n",
    "        pitch, allow_pickle=False\n",
    "    )\n",
    "\n",
    "_ = Parallel(n_jobs=16)(delayed(proc)(idx) for idx in range(len(all_wav_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([724, 80]),\n",
       " torch.Size([724]),\n",
       " torch.Size([724]),\n",
       " tensor(0.2604),\n",
       " tensor(133.3747))"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "i = 123\n",
    "\n",
    "mel_gt_name = os.path.join(\n",
    "    train_config.mel_ground_truth, \"ljspeech-mel-%05d.npy\" % (i+1))\n",
    "mel_gt_target = np.load(mel_gt_name)\n",
    "\n",
    "energy_gt_name = os.path.join(\n",
    "    train_config.energy_path, \"ljspeech-energy-%05d.npy\" % (i))\n",
    "energy_gt_target = np.load(energy_gt_name)\n",
    "\n",
    "pitch_gt_name = os.path.join(\n",
    "    train_config.pitch_path, \"ljspeech-pitch-%05d.npy\" % (i))\n",
    "pitch_gt_target = np.load(pitch_gt_name)\n",
    "\n",
    "mel_gt_target = torch.from_numpy(mel_gt_target)\n",
    "energy_gt_target = torch.from_numpy(energy_gt_target)\n",
    "pitch_gt_target = torch.from_numpy(pitch_gt_target)\n",
    "\n",
    "mel_gt_target.shape, energy_gt_target.shape, pitch_gt_target.shape, energy_gt_target.min(), energy_gt_target.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f084bdc6fb224c3a9e1a7d6d3093e2b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(0.017866513, 314.9619, 0.0, 861.0652680139365)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "e_scaler, p_scaler = StandardScaler(), StandardScaler()\n",
    "n_samples = len(os.listdir(train_config.energy_path))\n",
    "\n",
    "for index in tqdm(range(n_samples)):\n",
    "    energy_gt_name = os.path.join(train_config.energy_path, \"ljspeech-energy-%05d.npy\" % (index))\n",
    "    energy_gt_target = np.load(energy_gt_name)\n",
    "    pitch_gt_name = os.path.join(train_config.pitch_path, \"ljspeech-pitch-%05d.npy\" % (index))\n",
    "    pitch_gt_target = np.load(pitch_gt_name)\n",
    "    e_scaler.partial_fit(energy_gt_target.reshape((-1, 1)))\n",
    "    p_scaler.partial_fit(pitch_gt_target.reshape((-1, 1)))\n",
    "\n",
    "min_e, max_e, min_p, max_p = np.inf, -np.inf, np.inf, -np.inf\n",
    "for index in tqdm(range(n_samples)):\n",
    "    energy_gt_name = os.path.join(train_config.energy_path, \"ljspeech-energy-%05d.npy\" % (index))\n",
    "    energy_gt_target = np.load(energy_gt_name)\n",
    "    energy_gt_target = (energy_gt_target - e_scaler.mean_[0]) / e_scaler.scale_[0]\n",
    "    # np.save(energy_gt_name, energy_gt_target)\n",
    "    min_e = min(min_e, energy_gt_target.min())\n",
    "    max_e = max(max_e, energy_gt_target.max())\n",
    "\n",
    "    pitch_gt_name = os.path.join(train_config.pitch_path, \"ljspeech-pitch-%05d.npy\" % (index))\n",
    "    pitch_gt_target = np.load(pitch_gt_name)\n",
    "    pitch_gt_target = (pitch_gt_target - p_scaler.mean_[0]) / p_scaler.scale_[0]\n",
    "    # np.save(pitch_gt_name, pitch_gt_target)\n",
    "    min_p = min(min_p, pitch_gt_target.min())\n",
    "    max_p = max(max_p, pitch_gt_target.max())\n",
    "min_e, max_e, min_p, max_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('dla-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6f97379390cc30a580a3e0139ea8da8b74238e90bc9d87802f55491180d34dc4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
